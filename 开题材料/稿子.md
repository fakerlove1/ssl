各位老师，大家早上好，我叫李飞翔，今天我开题答辩的题目是基于混合Transformer的半监督肺结节分割模型。

一共分成四个部分，分别为选题来源及意义，国内外研究现状，研究内容与方案，时间进度安排。

首先介绍第一部分，选题来源。

**肺癌是发病率和死亡率增长最快，对人群健康和生命威胁最大的恶性肿瘤之一。**下图我们可看到我国的新增肺癌人数，是比较多的。肺癌早期的主要表现方式是肺结节，实现肺结节的早期诊断和治疗可有效提高患者的生存率。

LDCT已被广泛应用于肺结节的检测。但是需要放射科医生检查CT，这是非常**繁琐**的，且存在**漏检和误检**的可能。

第三，从右边的6附图中可以看出肺结节形态学特征复杂，很难进行分割。

下面可以从图中看出肺结节目前数据集的情况，少量的标注信息与大量的未标注信息。而目前基于深度学习的算法主要依靠训练数据，需要大量的手工标记数据用于训练。所以呢半监督学习就成为一种廉价与实用方法。

选题的意义

第一，减少影像医生的工作量，降低误诊率。

第2，降低漏检率

第3，降低对人工标注的需求量，充分利用未标注数据与有限的数据集，提高模型性能与泛化能力。

 

第2部分就是国内外研究现状

首先这个是从今年7月份综述里的截出来的图。下面是它的引用。描述的是2014年-2022年半监督医学图像分割学术发展趋势图。可以看出目前半监督医学图像分割是非常火热的

接下来，讲解一下半监督学习发展现状。

半监督学习大体上分为两类。一种的基于自训练的方式。一种是基于无监督正则化。

基于无监督正则化的方法里，还可以细分成以下3种。一致性学习，协同训练，对抗学习GAN

最后一类是最近几年流行的混合模型。

接下来看一下常见的半监督方法，

在19年以前，流行的就是基于一致性学习的。有$\pi$模型，Mean-Teacher模型，还有UDA模型。

但是20年出来的论文FixMatch，就打破了僵局，同时使用了伪标签和一致性学习两种策略，达到SOTA结果。

21年的FlexMatch是对FixMatch进行的改进。



半监督医学图像分割与半监督学习方法类似，也是分为2大类，与一个混合模型。

我们看一下，有哪些经典的模型

20年的CutMix-Seg使用Mean-Teacher模型，和CutMix的数据增强方式，进行半监督分割

21年的PseudoSeg，使用FixMatch的方式

21年的CPS，使用了交叉伪监督的半监督分割

22年的交叉教学Cross-Teaching ,结合了协同训练，进行半监督医学图像分割



接下来，讲一下全监督医学图像分割模型

大致分成3类，一类是CNN,一类是Transformer,第3类就是CNN+Transformer。各种改进的都有，有在backone上进行改进的，有采用双分支的，也有在架构上，进行融合的

下面是经典的模型

15年的Unet，18年的Unet++,19年的nnUnet,21年的TransUnet和nnFormer



接下来是第3章。研究内容与方法

我的第一个研究内容是如何提高主干网络的特征提取能力。

目前主干，就是两个2流派，一个卷积神经网络，一个Transformer,但是卷积神经网络在提取全局特征上有局限性，Transformer计算量巨大，且需要大量的医学数据，而肺结节的数据集比较少。

所以我研究混合Transformer网络，将CNN与Transformer融合成新的网络，CNN提取局部特征，Transformer提取全局特征，优势互补，达到准确分割肺结节的目的。



第2个研究内容就是提高伪标签的质量。

伪标签是有 未标注信息生成的。导致的结果就是伪标签质量不稳定，含有大量噪音，其中带噪的伪标签容易造成退化。

目前的做法是采用熵最小化原则，设置置信度阈值，对伪标签加以约束，只使用置信度较高的伪标签，熵最小

看上图，这个是模型输出的One-hot编码，左边的是高置信度，熵最小。意思为模型对肺结节的判断非常的自信。右边这个图是低置信度的标签。模型对于是不是肺结节非常的纠结。这种标签我们直接抛弃。



导致的后果就是 伪标签无法无法提高足够的信息量，数据集仅获得较小的扩充，无法满足Transformer训练需求，且整体带噪率高

所以我研究的是伪标签混合策略。

我们直接看图，让无标注数据通过模型，输出预测。上面是通过置信度阈值的可靠的伪标签，下面是未通过置信度阈值的不可靠伪标签，以前的做法是直接抛弃，但是现在我想利用这部分被抛弃的标签，做法呢就是与 通过置信度阈值的标签，进行混合。置信度较高的标签具有很高的混合比。利用Transformer对噪音有很好的鲁棒性的特点，来缓解加入置信度的伪标签带来的负面影响。随着时间的推移，混合将不断扩大，这样子的话，就能够实现大幅度扩充数据集，满足Transformer的训练，而且提高伪标签整体的质量。



我研究的第三点。就是在半监督分割模型训练后期，一般的扰动方式将不能让模型做出错误的判断，导致没有带来新的信息，一致性学习的效率会大幅度下降。

所以研究新的一致性正则化策略，

下面的图，是研究1,2,3个点，结合的整体架构，在交叉教学的基础进行改进，实现联合训练与联合教学的有效结合，就是这部分内容。有标签的数据，进行有监督训练，无标签的内容，进行一致性学习训练。



并结合基于插值和CutMix两种一致性正则化方案，对其进行融合与改进。就在图中的这部分。新的一致性正则化方案将对模型的预测结果生成具有挑战性的对抗性噪音，使得模型在训练后期依旧保持较高的效率与稳定。一次来增强分割模型的泛化能力。



这部分就是我第一点内容。来增强模型的提取特征的能力，这部分就是我第2点，来扩充数据集，达到训练Transformer，这个部分就是我刚刚讲的第3点。以上我模型的整体架构。



下面是已开展工作。

对数据集进行数据增强

下面是我跑的半监督分割模型的baseline,出来的结果



最后一部分是时间进度安排。



基于自训练的方式，它的训练流程呢？

，方法较多。

它的思想基于平滑性假设，就是一个表现很好的模型应该对输入数据以及他的某些变形表现稳定。比如人看到了一匹马的照片，不管是卡通的，还是旋转的，人都能准确的识别出这是一匹马。



一种是协同训练，一种是基于对抗学习就是GAN。

下面讲一下具体有哪些模型。半监督学习发展很早，上个世纪就有了。基本都是和机器学习方法集合的。

现在讲的是和深度学习结合的。









半监督方法发展大

[半监督分割 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/336997723)

[医学图像分割的半监督学习综述_不想敲代码的小杨的博客-CSDN博客](https://blog.csdn.net/weixin_43921949/article/details/126578130)

[[CVPR 2021\] CPS: 基于交叉伪监督的半监督语义分割 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/378120529)

[半监督的语义分割综述 - 科学猫 (scicat.cn)](http://www.scicat.cn/mm/20220314/186322.html)

**一致性判定**正是描述了其中一个属性，那就是一个表现很好的模型应该对输入数据以及他的某些变形表现稳定。比如人看到了一匹马的照片，不管是卡通的，还是旋转的，人都能准确的识别出这是一匹马。那半监督学习也是一样，我们想要我们的模型表现良好，表现和上限通过大量有标签数据训练的一样（足够鲁棒），那么我们的模型也应该拥有这个属性，即对输入数据的某种变化鲁棒，此类方法代表方法为Teacher-student Model, CCT模型等等，对应的半监督学习假设就是平滑性假设。

1. **熵最小化约束**是描述了另外一个属性，那就是一个表现良好的模型应该对输入数据具有较高置信度的预测。例如，我们的上限是由很多有标签数据训练的，那么对于大部分新的测试样本，该模型都应该有一个比较高置信度的评价(应该都在训练中见过)，拿概率来说，就是不是0，就是1，要么是，要么不是。我们希望我们的半监督模型也应该有这么良好的表现。所以，就可以对模型预测的置信度进行判定，希望预测的置信度越大，即熵越小。此类方法代表性的工作是基于各类伪标签的半监督学习方法等等，对应的半监督学习假设就是类间密度最小假设。



协同训练

将自训练中伪标签的生成方式扩展为通过多个模型预测并融合得到伪标签，进而迭代训练。

一般分成两种

协同训练算法将自训练算法进行了扩展，为了降低单一模型预测带来的局限性提出使用多个预训练的模型以综合预
测伪标签，通过模型间的融合来提升伪标签的质量。

注意的是，协同训练需要使不同的模型在预训练过程中相互独立以提取不同的知识，实现时通常需要将数据集进行额外的划分保证子集间存在差异性或利用同一数据的不同视图，这样在随后的训练阶段就可以通过在未标记数据上的预测来传播每个模型学到的知识达到相互补充的效果，最终得到更加鲁棒的网络



另一种常见的协同训练方式没有使用学生模型，而是使用了相互指导的学习策略，即每个模型使用其他模型融合得到的伪标签进行训练，从而直接学习互补的知识。在此基础之上为了进一步过滤噪声数据，Xia等［59］提出了基于不确定性的融合生成策略，通过添加 Dropout利用贝叶斯深度网络估计预测的不确定性，进而在融合阶段以加权和的方式生成更可信的伪标签。





比如： 为了获取独立的子数据集，Zhou 等利用器官分割中 3D 医学影像数据可以分解为不同的轴向视图（矢状面、冠状面和轴向）的特点



大多数现有的半监督学习（SSL）算法都倾向于通过扰动网络和/或数据来规范模型训练。观察到多/双任务学习关注具有固有预测扰动的不同级别的信息。



伪标签肯定不都是正确的，有很多错误的伪标签。

有错误的伪标签会带来噪音，影响模型稳定，过分自信的伪标签，没有带来新的信息，模型一直学习已知的知识，导致过拟合。

为了减少噪音对模型训练的影响，目前的做法呢？是使用置信度较高的伪标签，抛弃置信度较低的伪标签。

会造成2种情况，第一种情况，使用置信度较高的未标签导致的一个潜在问题是，在整个训练过程中，某些像素可能永远无法学习。如，如果模型不能令人满意地预测某一类（例如，图1中的椅子），则很难为此类像素分配准确的伪标签，这可能导致训练不足和分类不平衡。从这个角度来看，我们认为，为了充分利用未标记的数据，每个像素都应该得到适当的利用。

第2种，如果过分约束后的伪标签又无法提供足够的信息量

这样子模型会抛弃某一类型的结节或者对某一类型的结节分割精度低。显然这是不科学

![image-20221104222044043](picture/image-20221104222044043.png)





缺少数据是需要进行半监督学习的主要原因,而GAN的生成器本身就具有生成数据的能力，且在相互对抗的过程中不需要数据本身的标签，GAN 在半监督学习中得到了大量的应用与改进。

大致上分成两类



另一类方法结合了伪标签的思路，将分割网络作为生成器来产生分割图，进而将分类器（如 ResNet［7］）作为对抗网络中的判别器用于评估分割网络预测的伪标签质量，从而监督分割网络生成更真实的预测结果。

其中代表性的算法是 Zhang 等［73］提出的深度对抗网络（Deep Adversarial Network，DAN）框架，DAN 将对抗网络应用于腺体分割与真菌分割任务，首先在有标记数据上预训练分割网络，在加入无标记数据后定义了判别网络来评价分割网络的预测质量，使其在训练过程中判断分割结果是否来源于训练过的有标记数据，最后固定训练好的判别器，鼓励分割网络欺骗评价网络，使其对所有数据的分割结果都判定为有标记数据，以此促使分割网络从对抗学习的过程中提高预测的质量





FixMatch 在强弱干扰下对相同未标记图像的一致性预测



传统的Pseudo Label方法，通常设定一个阈值，当模型预测样本属于某类的概率超过阈值时，给样本贴上相应的伪标签并用于训练；或者，直接选取模型预测的最大概率所在的类作为伪标签，其公式如下：





CPS 论文讲解 

[[CVPR 2021\] CPS: 基于交叉伪监督的半监督语义分割 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/378120529)

