1. **一致性判定**正是描述了其中一个属性，那就是一个表现很好的模型应该对输入数据以及他的某些变形表现稳定。比如人看到了一匹马的照片，不管是卡通的，还是旋转的，人都能准确的识别出这是一匹马。那半监督学习也是一样，我们想要我们的模型表现良好，表现和上限通过大量有标签数据训练的一样（足够鲁棒），那么我们的模型也应该拥有这个属性，即对输入数据的某种变化鲁棒，此类方法代表方法为Teacher-student Model, CCT模型等等，对应的半监督学习假设就是平滑性假设。
2. **熵最小化约束**是描述了另外一个属性，那就是一个表现良好的模型应该对输入数据具有较高置信度的预测。例如，我们的上限是由很多有标签数据训练的，那么对于大部分新的测试样本，该模型都应该有一个比较高置信度的评价(应该都在训练中见过)，拿概率来说，就是不是0，就是1，要么是，要么不是。我们希望我们的半监督模型也应该有这么良好的表现。所以，就可以对模型预测的置信度进行判定，希望预测的置信度越大，即熵越小。此类方法代表性的工作是基于各类伪标签的半监督学习方法等等，对应的半监督学习假设就是类间密度最小假设。



协同训练

将自训练中伪标签的生成方式扩展为通过多个模型预测并融合得到伪标签，进而迭代训练。

一般分成两种

协同训练算法将自训练算法进行了扩展，为了降低单一模型预测带来的局限性提出使用多个预训练的模型以综合预
测伪标签，通过模型间的融合来提升伪标签的质量。

注意的是，协同训练需要使不同的模型在预训练过程中相互独立以提取不同的知识，实现时通常需要将数据集进行额外的划分保证子集间存在差异性或利用同一数据的不同视图，这样在随后的训练阶段就可以通过在未标记数据上的预测来传播每个模型学到的知识达到相互补充的效果，最终得到更加鲁棒的网络



另一种常见的协同训练方式没有使用学生模型，而是使用了相互指导的学习策略，即每个模型使用其他模型融合得到的伪标签进行训练，从而直接学习互补的知识。在此基础之上为了进一步过滤噪声数据，Xia等［59］提出了基于不确定性的融合生成策略，通过添加 Dropout利用贝叶斯深度网络估计预测的不确定性，进而在融合阶段以加权和的方式生成更可信的伪标签。





比如： 为了获取独立的子数据集，Zhou 等利用器官分割中 3D 医学影像数据可以分解为不同的轴向视图（矢状面、冠状面和轴向）的特点



大多数现有的半监督学习（SSL）算法都倾向于通过扰动网络和/或数据来规范模型训练。观察到多/双任务学习关注具有固有预测扰动的不同级别的信息。



伪标签肯定不都是正确的，有很多错误的伪标签。

有错误的伪标签会带来噪音，影响模型稳定，过分自信的伪标签，没有带来新的信息，模型一直学习已知的知识，导致过拟合。

为了减少噪音对模型训练的影响，目前的做法呢？是使用置信度较高的伪标签，抛弃置信度较低的伪标签。

会造成2种情况，第一种情况，使用置信度较高的未标签导致的一个潜在问题是，在整个训练过程中，某些像素可能永远无法学习。如，如果模型不能令人满意地预测某一类（例如，图1中的椅子），则很难为此类像素分配准确的伪标签，这可能导致训练不足和分类不平衡。从这个角度来看，我们认为，为了充分利用未标记的数据，每个像素都应该得到适当的利用。

第2种，如果过分约束后的伪标签又无法提供足够的信息量

这样子模型会抛弃某一类型的结节或者对某一类型的结节分割精度低。显然这是不科学

![image-20221104222044043](picture/image-20221104222044043.png)





缺少数据是需要进行半监督学习的主要原因,而GAN的生成器本身就具有生成数据的能力，且在相互对抗的过程中不需要数据本身的标签，GAN 在半监督学习中得到了大量的应用与改进。

大致上分成两类



另一类方法结合了伪标签的思路，将分割网络作为生成器来产生分割图，进而将分类器（如 ResNet［7］）作为对抗网络中的判别器用于评估分割网络预测的伪标签质量，从而监督分割网络生成更真实的预测结果。

其中代表性的算法是 Zhang 等［73］提出的深度对抗网络（Deep Adversarial Network，DAN）框架，DAN 将对抗网络应用于腺体分割与真菌分割任务，首先在有标记数据上预训练分割网络，在加入无标记数据后定义了判别网络来评价分割网络的预测质量，使其在训练过程中判断分割结果是否来源于训练过的有标记数据，最后固定训练好的判别器，鼓励分割网络欺骗评价网络，使其对所有数据的分割结果都判定为有标记数据，以此促使分割网络从对抗学习的过程中提高预测的质量





FixMatch 在强弱干扰下对相同未标记图像的一致性预测



传统的Pseudo Label方法，通常设定一个阈值，当模型预测样本属于某类的概率超过阈值时，给样本贴上相应的伪标签并用于训练；或者，直接选取模型预测的最大概率所在的类作为伪标签，其公式如下：





CPS 论文讲解 

[[CVPR 2021\] CPS: 基于交叉伪监督的半监督语义分割 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/378120529)

