

# 小样本

## 1. 简介



### 1.1 基本概念

* **Zore-shot learning**，零样本学习。支持集为训练集，其为带标签的seen classes，查询集为测试集即unseen classes，零样本学习将识别与每个没见过的类在语义上与见过的类之间的相关知识。也就是，如果我们知道马长什么样子，知道斑马长得像马且有条纹，那么我们就算没见过也可以识别出斑马。
* **One-shot learning**，一样本学习。即当新未见过的类别只有一个的样本时，希望模型可以通过已经学习到的旧类别去预测新类别。此时的meta-learing就不是想传统监督学习那样，为了总结某个类的分布中存在的共享信息和模式，而是试图学习存在于任务分布上的规律（也就是怎么去学习）。
* **Few-shot learning**，少样本学习。机器学习模型在学习了一定类别的大量数据后，新的未见类是少量的样本就能快速学习。
* **C-way K-shot 问题**。训练集中有很多类别，选出C个类别，每个类别选出K个样本，作为支持集，再从C个类别中抽取剩余的batch作为测试集。


可以参考值这个视频

https://www.bilibili.com/video/BV1V44y1r7cx





### 1.2 什么叫小样本(Few shot)



![image-20221101215855296](picture/image-20221101215855296.png)



因为这个需求，所以诞生了小样本学习这个领域。

小样本学习的意思就是，人有仅靠少量数据，就可区分图片的能力，现在让模型也拥有这样子的模型



![image-20221101215815087](picture/image-20221101215815087.png)





## 2. 如何解决小样本问题



* 基于模型微调:首先在含有大量数据的源数据集上训练一个分类模型，然后在含有少量数据的目标数据集上对模型进行微调;
* 基于数据增强:利用辅助数据集或者辅助信息增强目标数据集中样本的特征或扩充目标数据集--基于无标签数据、基于数据合成和基于特征增强;
* 基于迁移学习:将已经学会的知识迁移到一个新领域
  * 基于度量学习
  * 基于元学习
  * 基于图神经网络;



![image-20221101220131080](picture/image-20221101220131080.png)



这里重点讲解 基于迁移学习的内容

### 2.1 元学习(一种架构)

#### 1) 概念

> 元学习（Meta-Learing），又称“学会学习“（Learning to learn）, 即利用以往的知识经验来指导新任务的学习，使网络具备学会学习的能力，是解决小样本问题（Few-shot Learning）常用的方法之一，



**元学习中的”元“是什么意思？**

元学习的本质是增加学习器在多任务的泛化能力，元学习对于任务和数据都需要采样，因此学习到的 F(x) 可以在未出现的任务中迅速（依赖很少的样本）建立起mapping。因此”元“体现在网络对于每个任务的学习，通过不断的适应每个具体任务，使网络具备了一种抽象的学习能力。



**元学习中的训练和测试？**

Meta-learning中为了区别概念，将训练过程定义为”Meta-training“、测试过程定义为”Meta-testing“, 如下图所示：

![img](picture/v2-a366b06c8015a2a44539a54b4b62b3e9_720w.webp)

如上图，区别于一般神经网络端到端的训练方式，元学习的训练过程和测试过程各需要两类
数据集（Support/Query set），其构建方式为：

![img](picture/v2-a4a973582683ba3f7008b69da1996c4e_720w.webp)

如上图所示的小样本分类任务属于” N-way k-shot“问题，**其中，N代表选择的Testing data**
**中样本的种类，k代表选择的K类Testing data中每类样本的数量，一般来说N小于Testing**
**data的总类别数。**

* 如何构建S’和Q‘?
  我们从Testing data中随机选出 N 个类。然后，再从这 N 个类中按照类别依次随机选出 k+x
  个样本（x 代表可以选任意个），其中的 k 个样本将被用作 Support set S'，另外的 x 个样
  本将被用作 Query set Q'。S和Q的构建同理，不同的是从Training data中选择的样本类别和
  每类样本数量均不做约束。
* 如何训练？
  Meta-learning 通常采用一种被称为 Episodic Training 的方法来进行训练。



**元学习和迁移学习的区别和联系？**

从目标上看，元学习和迁移学习的本质都是增加学习器在多任务的范化能力，但元学习更偏重于任务和数据的双重采样，即任务和数据一样是需要采样的，具体来说对于一个10分类任务，元学习通过可能只会建立起一个5分类器，每个训练的episode都可以看成是一个子任务，而学习到的F(x)可以帮助在未见过的任务里迅速建立mapping。而迁移学习更多是指从一个任务到其它任务的能力迁移，不太强调任务空间的概念。



#### 2) 解决方案

**元学习只是一种架构，具体的解决方法如下**

* 基于优化的方法的元学习
* 基于度量的方法的元学习
* 基于网络结构的元学习



参考资料

https://blog.csdn.net/weixin_39584888/article/details/122506902

### 2.2 度量学习(一种方法)



#### 1) 概念

> * 那么什么是度量学习呢？**度量学习(Metric Learning) 是人脸识别中常用的传统机器学习方法，由Eric Xing在NIPS 2002提出**，可以分为两种：一种是通过线性变换的度量学习，另一种是通过非线性变化的度量。
> * 其基本原理是根据不同的任务来自主学习出针对某个特定任务的度量距离函数。度量学习（Metric Learning）是一种空间映射的方法，其能够学习到一种特征（Embedding）空间，在此空间中，所有的数据都被转换成一个特征向量，并且相似样本的特征向量之间距离小，不相似样本的特征向量之间距离大，从而对数据进行区分。
> * 度量学习应用在很多领域中，比如图像检索，人脸识别，目标跟踪等等。后来度量学习又被迁移至文本分类领域，尤其是针对高维数据的文本处理，度量学习有很好的分类效果。

度量学习解决的问题不一定是few shot的问题。也可以说其他方面的问题，比如人脸识别，目标跟踪等等。

![image-20221101220330869](picture/image-20221101220330869.png)



#### 2) 基于度量的元学习方法

> 重点讲一下这个
>
> 参考资料：https://blog.csdn.net/weixin_39584888/article/details/122506902

接下来整理一些比较有代表性的度量学习文章：

**Siamese Neural Networks(孪生网络)**

孪生神经网络是一种相似性度量模型，当类别数多但每个类别的样本数量少的情况下可用于类别的识别。主要思想是通过嵌入函数将输入映射到目标空间，使用简单的距离函数进行相似度计算，然后在训练阶段最小化一对相同类别样本pair的损失同时最大化一对不同类别样本pair的损失。

模型结果如上图，先用cnn 提取特征Embedding，然后计算距离最后预测概率这两个输入是否是same class，同类为1，不同为0，损失计算是交叉熵。之所以叫孪生是因为两个孪生神经网络共享一套参数和权重（即一个cnn来抽特征）。

然后看看test阶段如何做的，比如对于one-shot来说，由于训练集中每个类别只有一个样本，所以测试集中的每张图像和训练集中的每个样本都组成一个样本对，依次输入到孪生神经网络中，得到每对样本的距离，选取距离最小的训练样本的标签作为测试样本的类别，从而完成分类。
![在这里插入图片描述](picture/20210206164359319.jpg)

**Match Network**

也是度量学习，与上面那个不一样的地方在于其从一对以一变成了一对多的关系，如上图的输入变成了多个带类别的样本和不带类别的样本。所以该网络的目的是可以将带标签的小样本数据和不带标签的样本映射到对应的标签上。使用的网络同样是CNN，然后新样本会和每一个向量都计算相似度最后得到得分。

![在这里插入图片描述](picture/20210206165625516.jpg)

**Prototypical Networks**

同样的还有原型网络（Prototypical Networks），类似k-means，作者认为每个类别在向量空间中都存在一个原型，即类别的中心点，所以对于映射后的样本求均值得到某类别的原型，训练loss使同类样本接近，而不同类样本远离。但是因为样本量太少会导致分类边界偏差，所有可以使用半监督的想法做出一些改进：

* 所有的无标签数据都属于带标签的数据所属的类别，将无标签数据和带标签数据一起计算新的原型。
* 无标签数据要么属于带标签数据所属的类别，要么属于一个另外的类——干扰类(distractor class)。干扰类开始以原点(0,0)作为原型，模型学习的是干扰类的半径。

* 无标签数据要么属于已知的类别，要么被掩盖(masked)。



![在这里插入图片描述](picture/20210206170027847.jpg)



总结一下。。。。。。。

![在这里插入图片描述](picture/20210206170912908.jpg)



### 2.3 半监督学习

> 小样本学习技术主要研究如何利用少量有监督样本来解决机器学习任务。经常被提起的还有半监督学习，其主要区别在于，半监督学习是解决小样本学习问题的重要手段之一。



在许多ML的实际应用中，很容易找到海量的无类标签的样例，但需要使用特殊设备或经过昂贵且用时非常长的实验过程进行人工标记才能得到有类标签的样本，由此产生了极少量的有类标签的样本和过剩的无类标签的样例。因此，人们尝试将大量的无类标签的样例加入到有限的有类标签的样本中一起训练来进行学习，期望能对学习性能起到改进的作用，由此产生了SSL，
![img](picture/20191023111734550.png)



![image-20221102155232514](picture/image-20221102155232514.png)







## 3. 基于度量的元学习小样本语义分割



根据度量学习的参数是否可以更新，基于度量的元学习小样本语义分割分为两种



### 3.1 基于参数结构的小样本分割

![image-20221102103200099](picture/image-20221102103200099.png)



### 3.2 基于原型结构的小样本分割模型

![image-20221102103223912](picture/image-20221102103223912.png)

